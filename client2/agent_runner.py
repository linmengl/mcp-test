import json
from typing import Optional
from tool_call_manager import ToolCallManager
from prompt_manager import PromptManager
import util


class AgentRunner:
    def __init__(self, session, model_name="deepseek-r1:7b"):
        """
        session: MCP çš„ ClientSession å®žä¾‹
        model_name: æ¨¡åž‹åç§°ï¼ˆç”¨äºŽ Ollama è°ƒç”¨ï¼‰
        """
        self.session = session
        self.model_name = model_name
        self.prompt_mgr = PromptManager()

    async def run(self, user_query: str) -> str:
        """
        ç”¨æˆ·æé—®ä¸€æ¬¡ï¼ŒAgent è‡ªåŠ¨å¤„ç†æ‰€æœ‰å¤šè½®æŽ¨ç†å’Œå·¥å…·è°ƒç”¨ï¼Œè¿”å›žæœ€ç»ˆç­”æ¡ˆã€‚
        """
        self.prompt_mgr.reset()
        self.prompt_mgr.add_system(await self._build_system_prompt())
        self.prompt_mgr.add_user(user_query)

        while True:
            # è°ƒç”¨å¤§æ¨¡åž‹ç”Ÿæˆå›žå¤
            messages = self.prompt_mgr.get_messages()
            response_json = await util.ollama_chat(messages)
            response_content = response_json["message"]["content"]
            print(f"\nðŸ¤– Assistant Output:\n{response_content}\n")

            # åˆ¤æ–­æ˜¯å¦ä¸ºæœ€ç»ˆå›žå¤
            if "Final Answer:" in response_content:
                self.prompt_mgr.add_assistant_message(response_content)
                return response_content.split("Final Answer:")[1].strip()

            # å°è¯•è§£æžå·¥å…·è°ƒç”¨
            tool_calls = ToolCallManager.parse_tool_calls(response_content)
            self.prompt_mgr.add_assistant_message(response_content)

            if not tool_calls:
                # å·¥å…·è°ƒç”¨è§£æžå¤±è´¥ï¼Œç›´æŽ¥è¿”å›ž
                return response_content

            # æ‰§è¡Œå·¥å…·è°ƒç”¨å¹¶åŠ å…¥ä¸Šä¸‹æ–‡
            for tool_call in tool_calls:
                try:
                    tool_name = tool_call["tool"]
                    args = tool_call["arguments"]
                    result = await self.session.call_tool(tool_name, args)
                    self.prompt_mgr.add_tool_result(result, tool_name)
                except Exception as e:
                    error = {"error": str(e)}
                    self.prompt_mgr.add_tool_result(error, tool_call["tool"])

    async def _build_system_prompt(self) -> str:
        """
        æž„å»º system promptï¼Œåˆ—å‡ºæ‰€æœ‰å·¥å…·ã€‚
        """
        tool_response = await self.session.list_tools()
        tools = [{
            "name": t.name,
            "description": t.description,
            "input_schema": t.inputSchema
        } for t in tool_response.tools]
        return util.build_system_prompt(tools)