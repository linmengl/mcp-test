import asyncio
import httpx

async def main():
    ollama_url = "http://localhost:11434/api/chat"
    model_name = "deepseek-r1:7b"

    messages = [
        {
            "role": "system",
            "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥æ ¹æ®ç”¨æˆ·çš„è¯·æ±‚ï¼Œå¿…è¦æ—¶è°ƒç”¨å·¥å…·æ¥å®Œæˆä»»åŠ¡ã€‚\n"
                       "å·¥å…·å: get_alerts\nè¯´æ˜: Get weather alerts for a US state.\n"
                       "å‚æ•°ç»“æ„: {'properties': {'state': {'title': 'State', 'type': 'string'}}, 'required': ['state'], 'title': 'get_alertsArguments', 'type': 'object'}\n\n"
                       "å·¥å…·å: get_forecast\nè¯´æ˜: Get weather forecast for a location.\n"
                       "å‚æ•°ç»“æ„: {'properties': {'latitude': {'title': 'Latitude', 'type': 'number'}, 'longitude': {'title': 'Longitude', 'type': 'number'}}, 'required': ['latitude', 'longitude'], 'title': 'get_forecastArguments', 'type': 'object'}"
        },
        {
            "role": "user",
            "content": "ä½ å¥½"
        }
    ]

    payload = {
        "model": model_name,
        "messages": messages,
        "stream": False
    }

    async with httpx.AsyncClient(timeout=60) as client:
        response = await client.post(ollama_url, json=payload)
        response.raise_for_status()
        result = response.json()

    reply = result.get("message", {}).get("content", "[æœªè·å–åˆ°å›å¤]")
    print("ğŸ¤– æ¨¡å‹å›å¤ï¼š\n", reply)

if __name__ == "__main__":
    asyncio.run(main())